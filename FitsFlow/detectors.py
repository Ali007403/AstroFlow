# -*- coding: utf-8 -*-
"""detectors.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mgiCPWeh9yxe09QNeIY_QDEtRJBJHcgX
"""

# FitsFlow/detectors.py
"""
Anomaly detection helpers for spectra.

Functions:
- detect_outliers_zscore(fl, z_thresh=4)
- detect_flux_dips(wl, fl, window=101, depth_frac=0.01)
- detect_spikes(fl, window=11, std_factor=5)
- detect_anomalies(wl, fl, params) -> consolidated list
- annotate_plotly(fig, anomalies) -> add markers for anomalies
"""

import numpy as np
from typing import List, Dict, Any

def detect_outliers_zscore(flux: np.ndarray, z_thresh: float = 4.0) -> List[Dict[str, Any]]:
    """Simple z-score based outlier detection."""
    out = []
    if flux is None or len(flux) == 0:
        return out
    med = np.nanmedian(flux)
    mad = np.nanmedian(np.abs(flux - med)) + 1e-12
    z = (flux - med) / (1.4826 * mad)
    idx = np.where(np.abs(z) >= z_thresh)[0]
    for i in idx:
        out.append({"index": int(i), "value": float(flux[i]), "type": "outlier", "score": float(z[i])})
    return out

def moving_median(arr: np.ndarray, window: int):
    if window <= 1:
        return arr
    from numpy.lib.stride_tricks import sliding_window_view
    try:
        sw = sliding_window_view(arr, window)
        med = np.median(sw, axis=1)
        # pad to original length
        pad = (len(arr) - len(med)) // 2
        return np.pad(med, (pad, len(arr) - len(med) - pad), mode="edge")
    except Exception:
        # fallback to naive
        out = np.copy(arr)
        half = window // 2
        for i in range(len(arr)):
            l = max(0, i - half)
            r = min(len(arr), i + half + 1)
            out[i] = np.median(arr[l:r])
        return out

def detect_flux_dips(wl: np.ndarray, flux: np.ndarray, window: int = 101, depth_frac: float = 0.01) -> List[Dict[str, Any]]:
    """
    Detect local dips relative to rolling median.
    - window: smoothing window for reference median
    - depth_frac: fraction of continuum depth considered significant (e.g., 0.01 = 1%)
    """
    out = []
    if flux is None or len(flux) == 0:
        return out
    ref = moving_median(flux, window)
    # avoid divide by zero
    denom = np.where(ref == 0, np.nan, ref)
    depth = (ref - flux) / np.abs(denom)
    # identify contiguous regions above threshold
    mask = (depth >= depth_frac) & np.isfinite(depth)
    if not np.any(mask):
        return out
    # find segments
    idxs = np.where(mask)[0]
    # group contiguous indices
    groups = np.split(idxs, np.where(np.diff(idxs) != 1)[0] + 1)
    for g in groups:
        if len(g) == 0:
            continue
        center = int(g[len(g)//2])
        out.append({
            "index": center,
            "wl": float(wl[center]) if wl is not None else None,
            "value": float(flux[center]),
            "type": "dip",
            "depth_frac": float(np.nanmax(depth[g])),
            "width_px": int(len(g))
        })
    return out

def detect_spikes(flux: np.ndarray, window: int = 11, std_factor: float = 6.0) -> List[Dict[str, Any]]:
    """
    Detect narrow spikes where abs(flux - rolling_median) >> rolling_std.
    """
    out = []
    if flux is None or len(flux) == 0:
        return out
    med = moving_median(flux, window)
    resid = flux - med
    # rolling std approximation
    from scipy.ndimage import uniform_filter1d
    sq = resid**2
    var = uniform_filter1d(sq, size=window)
    rstd = np.sqrt(var)
    mask = np.abs(resid) > (std_factor * (rstd + 1e-12))
    idxs = np.where(mask)[0]
    for i in idxs:
        out.append({"index": int(i), "value": float(flux[i]), "type": "spike", "score": float(np.abs(resid[i]) / (rstd[i] + 1e-12))})
    return out

def detect_anomalies(wl: np.ndarray, fl: np.ndarray, params: Dict = None) -> List[Dict[str, Any]]:
    """
    High-level wrapper to run configured detectors and return consolidated anomalies list.
    params example:
        {"z_thresh":4, "dip_window":101, "dip_depth":0.01, "spike_window":11, "spike_std":6}
    """
    if params is None:
        params = {}
    out = []
    try:
        out += detect_outliers_zscore(fl, z_thresh=params.get("z_thresh", 4.0))
    except Exception:
        pass
    try:
        out += detect_flux_dips(wl, fl, window=params.get("dip_window", 101), depth_frac=params.get("dip_depth", 0.01))
    except Exception:
        pass
    try:
        out += detect_spikes(fl, window=params.get("spike_window", 11), std_factor=params.get("spike_std", 6.0))
    except Exception:
        pass
    # sort by index
    out_sorted = sorted(out, key=lambda x: x.get("index", 0))
    return out_sorted

def annotate_plotly(fig, anomalies: List[Dict[str, Any]], wl_field: str = "x", val_field: str = "y"):
    """
    Add anomaly markers to a Plotly figure.
    - fig: a plotly.graph_objects.Figure with a trace having x=wl, y=flux
    - anomalies: list of dicts with keys 'index', 'wl', 'value', 'type'
    returns fig (modified)
    """
    import plotly.graph_objects as go
    if not anomalies:
        return fig
    types = {}
    for a in anomalies:
        t = a.get("type", "anomaly")
        types.setdefault(t, []).append(a)
    color_map = {"dip": "red", "outlier": "orange", "spike": "magenta", "anomaly": "purple"}
    for t, items in types.items():
        xs = [it.get("wl", None) for it in items]
        ys = [it.get("value", None) for it in items]
        # fall back to index positions if wl missing
        if xs and xs[0] is None:
            xs = [it["index"] for it in items]
        fig.add_trace(go.Scatter(x=xs, y=ys, mode="markers", marker=dict(size=8, color=color_map.get(t, "purple")), name=f"{t}"))
    return fig