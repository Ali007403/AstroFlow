# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mgiCPWeh9yxe09QNeIY_QDEtRJBJHcgX
"""

# app.py
import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
from astropy.io import fits
from scipy.signal import savgol_filter
from scipy.optimize import curve_fit
import pandas as pd
import tempfile
import os
import io
from typing import Dict, Tuple, List

st.set_page_config(page_title="AstroFlow Â· FITS Processor", layout="wide")

# -------------------------
# Utility / Processing Code
# -------------------------

WL_COLS = ['WAVELENGTH', 'WAVE', 'LAMBDA', 'WLEN', 'LAMBDA_MICRON', 'LAMBDA_UM']
FLUX_COLS = ['FLUX', 'FLUX_DENSITY', 'SPECTRUM', 'INTENSITY', 'FLUX_1']

def safe_names(arr):
    """Return list of column names if numpy recarray/table, else empty."""
    try:
        return list(arr.names)
    except Exception:
        return []

def find_wl_flux_from_table(table):
    """Try to find wavelength and flux columns in an astropy table-like HDU data."""
    names = safe_names(table)
    wl_col = next((c for c in WL_COLS if c in names), None)
    flux_col = next((c for c in FLUX_COLS if c in names), None)
    return wl_col, flux_col

def interp_to_reference(wl, fl, ref_wl):
    # safe interpolation with nan handling
    try:
        return np.interp(ref_wl, wl, fl, left=np.nan, right=np.nan)
    except Exception:
        return np.full_like(ref_wl, np.nan)

def gaussian(x, mu, sigma, amp):
    return amp * np.exp(-0.5 * ((x - mu) / sigma) ** 2)

def gauss_fit(x, y, guess):
    """Fit a single gaussian to x,y around guess params (mu, sigma, amp)."""
    try:
        p0 = [guess.get('mu', x[np.nanargmax(y)]), guess.get('sigma', 0.02), guess.get('amp', np.nanmax(y) - np.nanmin(y))]
        popt, pcov = curve_fit(gaussian, x, y, p0=p0, maxfev=10000)
        return popt, np.sqrt(np.diag(pcov))
    except Exception:
        return None, None

def calc_snr_on_band(ref_wl, ref_flux, band_range: Tuple[float,float]):
    """Simple SNR calc: signal = depth compared to continuum; noise = std of adjacent windows."""
    start, end = band_range
    mask = (ref_wl >= start) & (ref_wl <= end)
    if not np.any(mask):
        return 0.0
    # signal as absolute deviation from local continuum (1 if normalized)
    signal = np.abs(1 - np.nanmean(ref_flux[mask]))
    # define noise windows adjacent
    left_mask = (ref_wl >= (start - 0.3)) & (ref_wl <= (start - 0.1))
    right_mask = (ref_wl >= (end + 0.1)) & (ref_wl <= (end + 0.3))
    noise_vals = []
    if np.any(left_mask):
        noise_vals.append(np.nanstd(ref_flux[left_mask]))
    if np.any(right_mask):
        noise_vals.append(np.nanstd(ref_flux[right_mask]))
    noise = np.nanmean(noise_vals) if noise_vals else np.nanstd(ref_flux)
    if noise == 0 or np.isnan(noise):
        return 0.0
    return signal / noise

def try_extract_spectrum(hdu):
    """
    Given an HDU (table or image), attempt to return wavelength, flux arrays (1D).
    Returns (wl, fl) or (None, None).
    """
    data = hdu.data
    hdr = hdu.header
    # Table-like
    if hasattr(data, 'names'):
        wl_col, fl_col = find_wl_flux_from_table(data)
        if wl_col and fl_col:
            wl = np.array(data[wl_col]).astype(float).flatten()
            fl = np.array(data[fl_col]).astype(float).flatten()
            mask = np.isfinite(wl) & np.isfinite(fl)
            return wl[mask], fl[mask]
        # fallback: try first two numeric columns
        names = safe_names(data)
        numeric_cols = [n for n in names if np.issubdtype(data[n].dtype, np.number)]
        if len(numeric_cols) >= 2:
            wl = np.array(data[numeric_cols[0]]).astype(float).flatten()
            fl = np.array(data[numeric_cols[1]]).astype(float).flatten()
            mask = np.isfinite(wl) & np.isfinite(fl)
            return wl[mask], fl[mask]
    # Image-like
    if data is not None:
        if data.ndim == 1:
            wl = np.arange(len(data))
            fl = data.astype(float)
            mask = np.isfinite(fl)
            return wl[mask], fl[mask]
        elif data.ndim == 2:
            # collapse along one axis (sum or mean) to create 1D spectrum
            fl = np.nanmean(data, axis=0)
            wl = np.arange(len(fl))
            mask = np.isfinite(fl)
            return wl[mask], fl[mask]
    return None, None

# -------------------------
# App UI and orchestration
# -------------------------

st.title("ðŸ”­ AstroFlow Â· FITSFlow Processor")
st.markdown("Upload FITS files (JWST/HST/TESS or generic) and get automatic spectrum extraction, stacking, smoothing, Gaussian fits and SNR analysis. Export CSV/PNG results.")

# Sidebar controls
st.sidebar.header("Analysis controls")
smoothing_window = st.sidebar.slider("Smoothing window (odd)", min_value=5, max_value=501, value=51, step=2)
polyorder = st.sidebar.slider("SavGol polyorder", min_value=1, max_value=5, value=3)
normalize = st.sidebar.checkbox("Normalize stacked spectrum", value=True)
do_stack = st.sidebar.checkbox("Stack all spectra (if multiple)", value=True)
do_gauss = st.sidebar.checkbox("Attempt Gaussian fit to strongest line in each spectrum", value=False)
show_headers = st.sidebar.checkbox("Show FITS headers", value=False)
download_all = st.sidebar.checkbox("Enable Export All buttons", value=True)

st.sidebar.markdown("---")
st.sidebar.markdown("Biosignature bands (Âµm) are overlaid on stacked plot for quick visual inspection.")
st.sidebar.markdown("Developed by FutureMind / AstroFlow")

# Upload section
uploaded_files = st.file_uploader("Upload one or more FITS files", type=["fits"], accept_multiple_files=True)

if not uploaded_files:
    st.info("Upload FITS files to begin. Example: K2-18b or GJ-1214b sample FITS.")
    st.stop()

# Create a temporary working dir for uploads
with tempfile.TemporaryDirectory() as tmpdir:
    file_paths = []
    for up in uploaded_files:
        path = os.path.join(tmpdir, up.name)
        with open(path, "wb") as f:
            f.write(up.read())
        file_paths.append(path)

    # Container for per-file results
    all_spectra = []  # list of dicts: {'file':..., 'hdu_index':..., 'wl':..., 'fl':..., 'header':...}
    progress_bar = st.progress(0)
    total_files = len(file_paths)
    idx_file = 0

    for path in file_paths:
        idx_file += 1
        progress_bar.progress(int((idx_file-1) / total_files * 100))
        st.write(f"### ðŸ”Ž Processing `{os.path.basename(path)}`")
        try:
            with fits.open(path, memmap=False) as hdul:
                # show basic hdul info
                hdunames = [ (i, hdu.header.get('XTENSION', 'PRIMARY'), None if hdu.data is None else getattr(hdu.data, 'shape', None)) for i,hdu in enumerate(hdul) ]
                if show_headers:
                    st.write("HDU list (index, type, shape):", hdunames)

                # Try to extract 1D spectra from any HDU
                found = False
                for i,hdu in enumerate(hdul):
                    wl, fl = try_extract_spectrum(hdu)
                    if wl is None:
                        # no spectrum in this HDU
                        continue
                    found = True
                    # store
                    all_spectra.append({'file': os.path.basename(path), 'path': path, 'hdu_index': i,
                                        'wl': np.array(wl, dtype=float), 'fl': np.array(fl, dtype=float),
                                        'header': dict(hdu.header)})
                # If no spectrum found, show HDU images or tables
                if not found:
                    st.warning("No 1D spectrum found automatically in any HDU. Showing HDU summaries.")
                    for i,hdu in enumerate(hdul):
                        if hdu.data is None:
                            continue
                        if getattr(hdu.data, 'ndim', 0) == 2:
                            fig, ax = plt.subplots(figsize=(6,3))
                            ax.imshow(hdu.data, origin='lower', aspect='auto', cmap='gray')
                            ax.set_title(f"{os.path.basename(path)} - HDU {i} Image")
                            st.pyplot(fig)
                        elif getattr(hdu.data, 'ndim', 0) == 1:
                            fig, ax = plt.subplots(figsize=(6,3))
                            ax.plot(hdu.data)
                            ax.set_title(f"{os.path.basename(path)} - HDU {i} 1D")
                            st.pyplot(fig)
        except Exception as e:
            st.error(f"Failed to read {path}: {e}")

    progress_bar.progress(100)

    # If we have spectra, present them
    if len(all_spectra) == 0:
        st.info("No spectra auto-extracted. Consider checking table column names or providing pre-processed CSV spectra.")
        st.stop()

    # Optionally stack spectra
    st.markdown("## ðŸ”¬ Per-file / per-HDU results")
    for spec in all_spectra:
        file_label = f"{spec['file']} (HDU {spec['hdu_index']})"
        with st.expander(file_label, expanded=False):
            wl = spec['wl']
            fl = spec['fl']
            header = spec['header']

            # Basic table / header
            if show_headers:
                st.subheader("Header")
                st.json(header)

            # Normalize if requested
            fl_proc = fl.copy().astype(float)
            if normalize:
                if np.nanmax(fl_proc) - np.nanmin(fl_proc) != 0:
                    fl_proc = (fl_proc - np.nanmin(fl_proc)) / (np.nanmax(fl_proc) - np.nanmin(fl_proc))

            # Smoothing (Savitzky-Golay) if series long enough
            try:
                if len(fl_proc) >= smoothing_window:
                    fl_smooth = savgol_filter(fl_proc, smoothing_window if smoothing_window % 2 == 1 else smoothing_window+1, polyorder)
                else:
                    fl_smooth = fl_proc
            except Exception:
                fl_smooth = fl_proc

            # Plot raw + smoothed
            fig, ax = plt.subplots(figsize=(9,3))
            ax.plot(wl, fl_proc, label='raw', alpha=0.6)
            ax.plot(wl, fl_smooth, label='smoothed', linewidth=1.2)
            ax.set_xlabel("Wavelength")
            ax.set_ylabel("Flux (normalized)" if normalize else "Flux")
            ax.set_title(file_label)
            ax.grid(True)
            ax.legend()
            st.pyplot(fig)

            # Gaussian fit (optional)
            if do_gauss:
                # fit strongest local max area: find top peak
                try:
                    # work on smoothed
                    peak_idx = np.nanargmax(fl_smooth)
                    peak_wl = wl[peak_idx]
                    # choose window around peak for fitting
                    half_width = max(3, int(len(wl) * 0.01))  # ~1% of length
                    fit_mask = (wl >= max(min(wl), peak_wl - 0.1)) & (wl <= min(max(wl), peak_wl + 0.1))
                    if np.sum(fit_mask) >= 5:
                        xfit = wl[fit_mask]
                        yfit = fl_smooth[fit_mask]
                        guess = {'mu': peak_wl, 'sigma': 0.02, 'amp': np.nanmax(yfit)-np.nanmin(yfit)}
                        popt, perr = gauss_fit(xfit, yfit, guess)
                        if popt is not None:
                            ax.plot(xfit, gaussian(xfit, *popt), 'r--', label='gauss fit')
                            st.pyplot(fig)  # re-show with fit
                            st.write("Gaussian params (mu, sigma, amp):", np.round(popt,5))
                    else:
                        st.write("Gaussian fit skipped (insufficient points in fit window).")
                except Exception as e:
                    st.write("Gaussian fit failed:", e)

            # SNR per target biosignature bands (example bands, in same units as wl)
            bands = {'H2O': (1.35,1.45), 'CH4': (1.60,1.72), 'CO2':(2.65,2.75)}
            st.write("SNR in selected bands (approx.):")
            snr_list = {}
            for mol, rng in bands.items():
                snr = calc_snr_on_band(wl, fl_smooth, rng)
                snr_list[mol] = float(np.round(snr,3))
                st.write(f"{mol}: {snr_list[mol]} Ïƒ")

            # Allow downloads: CSV for wl+flux and PNG for last figure
            df_out = pd.DataFrame({'wavelength': wl, 'flux': fl_proc, 'flux_smoothed': fl_smooth})
            csv_bytes = df_out.to_csv(index=False).encode('utf-8')
            st.download_button(label="Download CSV (wavelength,flux,smoothed)", data=csv_bytes, file_name=f"{spec['file']}_hdu{spec['hdu_index']}.csv", mime='text/csv')

            # Save PNG to bytes
            png_buf = io.BytesIO()
            fig.savefig(png_buf, format='png', bbox_inches='tight')
            png_buf.seek(0)
            st.download_button(label="Download plot (PNG)", data=png_buf, file_name=f"{spec['file']}_hdu{spec['hdu_index']}.png", mime='image/png')

    # If stacking enabled and more than one spectrum
    if do_stack and len(all_spectra) >= 2:
        st.markdown("## ðŸ”— Stacked spectrum")
        # determine reference wavelength grid across all spectra
        min_wl = min(np.min(s['wl']) for s in all_spectra)
        max_wl = max(np.max(s['wl']) for s in all_spectra)
        ref_wl = np.linspace(min_wl, max_wl, 2000)
        interp_fluxes = []
        for s in all_spectra:
            interp_fluxes.append(interp_to_reference(s['wl'], s['fl'], ref_wl))
        stacked = np.nanmean(interp_fluxes, axis=0)
        # normalize if requested
        if normalize:
            stacked = (stacked - np.nanmin(stacked)) / (np.nanmax(stacked) - np.nanmin(stacked))
        # smooth
        if len(stacked) >= smoothing_window:
            stacked_smoothed = savgol_filter(np.nan_to_num(stacked, nan=np.nanmean(stacked)), smoothing_window if smoothing_window%2==1 else smoothing_window+1, polyorder)
        else:
            stacked_smoothed = stacked

        # overlay simulated biosignature markers (just visual)
        bio_bands = {'H2O': (1.35,1.45), 'CH4': (1.60,1.72), 'CO2': (2.65,2.75)}
        fig2, ax2 = plt.subplots(figsize=(10,4))
        ax2.plot(ref_wl, stacked_smoothed, color='black', label='stacked (smoothed)')
        colors = ['skyblue','violet','lightgreen']
        for i,(mol,(a,b)) in enumerate(bio_bands.items()):
            ax2.axvspan(a,b, color=colors[i], alpha=0.25, label=mol)
        ax2.set_xlabel("Wavelength")
        ax2.set_ylabel("Normalized flux" if normalize else "Flux")
        ax2.set_title("Stacked Spectrum")
        ax2.legend()
        ax2.grid(True)
        st.pyplot(fig2)

        # SNR summary for stacked
        st.write("Stacked SNR:")
        stacked_snrs = {}
        for mol, rng in bio_bands.items():
            snr = calc_snr_on_band(ref_wl, stacked_smoothed, rng)
            stacked_snrs[mol] = float(np.round(snr,3))
            st.write(f"{mol}: {stacked_snrs[mol]} Ïƒ")

        # allow download of stacked CSV + PNG
        df_stack = pd.DataFrame({'wavelength': ref_wl, 'stacked': stacked, 'stacked_smoothed': stacked_smoothed})
        st.download_button("Download stacked CSV", df_stack.to_csv(index=False).encode('utf-8'), file_name="stacked_spectrum.csv", mime='text/csv')
        png_buf2 = io.BytesIO()
        fig2.savefig(png_buf2, format='png', bbox_inches='tight')
        png_buf2.seek(0)
        st.download_button("Download stacked PNG", png_buf2, file_name="stacked_spectrum.png", mime='image/png')

    st.success("All results displayed above. You can expand any result card to see raw headers, plots, and download outputs.")


